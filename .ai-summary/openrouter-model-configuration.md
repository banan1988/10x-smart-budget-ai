# Konfiguracja Modelu OpenRouter

## Jak zmieniƒá model?

### 1. Edytuj plik `.env`

```bash
# W pliku .env
OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct:free
```

### 2. Restart aplikacji

Po zmianie zmiennej ≈õrodowiskowej, zrestartuj serwer deweloperski.

---

## Zalecane Modele

### üÜì Darmowe Modele (Recommended dla development)

#### ‚≠ê **Llama 3.2 3B Instruct** (ZALECANY)
```
OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct:free
```
- **Koszt**: $0 (darmowy)
- **Jako≈õƒá**: Bardzo dobra dla structured output
- **Szybko≈õƒá**: Wysoka
- **Context**: 128k tokens
- **Ograniczenia**: 20 requests/minute
- **U≈ºycie**: ‚úÖ Idealny na poczƒÖtek!

#### Llama 3.2 1B Instruct
```
OPENROUTER_MODEL=meta-llama/llama-3.2-1b-instruct:free
```
- **Koszt**: $0 (darmowy)
- **Jako≈õƒá**: Dobra (ni≈ºsza ni≈º 3B)
- **Szybko≈õƒá**: Bardzo wysoka
- **Context**: 128k tokens
- **U≈ºycie**: Je≈õli potrzebujesz bardzo szybkich odpowiedzi

#### Google Gemini 2.0 Flash
```
OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free
```
- **Koszt**: $0 (darmowy w wersji experimental)
- **Jako≈õƒá**: Bardzo dobra
- **Szybko≈õƒá**: Wysoka
- **Context**: 1M tokens (!)
- **U≈ºycie**: Alternatywa dla Llama

---

### üí∞ P≈Çatne Modele (Recommended dla production)

#### ‚≠ê **GPT-4o Mini** (NAJLEPSZY STOSUNEK CENY DO JAKO≈öCI)
```
OPENROUTER_MODEL=openai/gpt-4o-mini
```
- **Koszt**: $0.15 input / $0.60 output per 1M tokens
- **Jako≈õƒá**: Bardzo dobra
- **Szybko≈õƒá**: Wysoka
- **Context**: 128k tokens
- **Koszt typowej kategoryzacji**: ~$0.00006 (0.006 centa)
- **U≈ºycie**: ‚úÖ Najlepszy wyb√≥r dla production

#### Claude 3.5 Sonnet
```
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```
- **Koszt**: $3.00 input / $15.00 output per 1M tokens
- **Jako≈õƒá**: Najwy≈ºsza
- **Szybko≈õƒá**: ≈örednia
- **Context**: 200k tokens
- **Koszt typowej kategoryzacji**: ~$0.0012 (0.12 centa)
- **U≈ºycie**: Gdy potrzebujesz najwy≈ºszej jako≈õci

#### Claude 3.5 Haiku
```
OPENROUTER_MODEL=anthropic/claude-3.5-haiku
```
- **Koszt**: $0.80 input / $4.00 output per 1M tokens
- **Jako≈õƒá**: Bardzo dobra
- **Szybko≈õƒá**: Bardzo wysoka
- **Context**: 200k tokens
- **Koszt typowej kategoryzacji**: ~$0.00032 (0.032 centa)
- **U≈ºycie**: Dobra alternatywa dla GPT-4o Mini

#### GPT-4o
```
OPENROUTER_MODEL=openai/gpt-4o
```
- **Koszt**: $2.50 input / $10.00 output per 1M tokens
- **Jako≈õƒá**: Bardzo wysoka
- **Szybko≈õƒá**: ≈örednia
- **Context**: 128k tokens
- **Koszt typowej kategoryzacji**: ~$0.001 (0.1 centa)
- **U≈ºycie**: Premium opcja

---

## Szacowanie Koszt√≥w

### Przyk≈Çadowa Kategoryzacja

**Typowy request (200 tokens):**
```
System Prompt: ~150 tokens
User Prompt: ~20 tokens
Response: ~30 tokens
TOTAL: ~200 tokens
```

### Koszty dla 10,000 kategoryzacji/miesiƒÖc:

| Model | Koszt/miesiƒÖc | Koszt/kategoryzacja |
|-------|---------------|---------------------|
| Llama 3.2 3B (free) | **$0** | $0 |
| GPT-4o Mini | **$1.50** | $0.00015 |
| Claude 3.5 Haiku | $3.60 | $0.00036 |
| GPT-4o | $12.50 | $0.00125 |
| Claude 3.5 Sonnet | $36.00 | $0.0036 |

---

## Strategia Rekomendowana

### Development
```bash
# .env.development
OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct:free
```
‚úÖ Darmowy, dobra jako≈õƒá, wystarczajƒÖca szybko≈õƒá

### Production (Ma≈Çe/≈örednie obciƒÖ≈ºenie)
```bash
# .env.production
OPENROUTER_MODEL=openai/gpt-4o-mini
```
‚úÖ Najlepszy stosunek ceny do jako≈õci (~$1.50/10k kategoryzacji)

### Production (Du≈ºe obciƒÖ≈ºenie + wymagana jako≈õƒá)
```bash
# .env.production
OPENROUTER_MODEL=anthropic/claude-3.5-haiku
```
‚úÖ Szybki, dobra jako≈õƒá, rozsƒÖdna cena

### Production (Krytyczna jako≈õƒá)
```bash
# .env.production
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```
‚úÖ Najwy≈ºsza jako≈õƒá, wy≈ºsza cena

---

## Testowanie R√≥≈ºnych Modeli

### Zmie≈Ñ model w `.env`:
```bash
OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct:free
```

### Przetestuj kategoryzacjƒô:
```typescript
const service = new AiCategorizationService();

const testCases = [
  'Coffee at Starbucks',
  'Uber ride to airport',
  'Netflix subscription',
  'Tesco grocery shopping',
];

for (const description of testCases) {
  const result = await service.categorizeTransaction(description);
  console.log(`${description}:`);
  console.log(`  Category: ${result.categoryKey}`);
  console.log(`  Confidence: ${result.confidence}`);
  console.log(`  Reasoning: ${result.reasoning}\n`);
}
```

### Por√≥wnaj wyniki r√≥≈ºnych modeli:
1. Jako≈õƒá kategoryzacji (accuracy)
2. Confidence scores
3. Reasoning quality
4. Szybko≈õƒá odpowiedzi
5. Koszt

---

## FAQ

**Q: Kt√≥ry model wybraƒá na start?**  
A: `meta-llama/llama-3.2-3b-instruct:free` - darmowy i wystarczajƒÖco dobry.

**Q: Czy mogƒô u≈ºywaƒá r√≥≈ºnych modeli dla r√≥≈ºnych u≈ºytkownik√≥w?**  
A: Obecnie nie, ale mo≈ºna to zaimplementowaƒá przekazujƒÖc model jako parametr do serwisu.

**Q: Czy darmowe modele majƒÖ limity?**  
A: Tak, zazwyczaj ~20 requests/minute. Dla wiƒôkszego ruchu u≈ºyj p≈Çatnego modelu.

**Q: Jak monitorowaƒá koszty?**  
A: OpenRouter dashboard pokazuje usage. Mo≈ºesz te≈º dodaƒá w≈Çasny monitoring w kodzie.

**Q: Co je≈õli model zwr√≥ci z≈ÇƒÖ kategoriƒô?**  
A: U≈ºytkownik mo≈ºe poprawiƒá + zapisz feedback. W przysz≈Ço≈õci mo≈ºna u≈ºyƒá tego do fine-tuningu.

**Q: Czy mogƒô u≈ºyƒá lokalnego modelu?**  
A: Tak, mo≈ºesz skonfigurowaƒá w≈Çasny endpoint, ale OpenRouter jest wygodniejszy.

---

## Przyk≈Çad: Zmiana Modelu

### 1. Development ‚Üí Production

**Przed (development):**
```bash
# .env
OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct:free
```

**Po (production):**
```bash
# .env
OPENROUTER_MODEL=openai/gpt-4o-mini
```

### 2. Restart aplikacji

```bash
npm run dev  # development
# lub
npm run build && npm start  # production
```

### 3. Verify w logach

Sprawd≈∫ ≈ºe aplikacja u≈ºywa nowego modelu:
```
[AiCategorizationService] Using model: openai/gpt-4o-mini
```

---

## Monitoring Koszt√≥w

### TODO: Implementacja
```typescript
// Dodaj do AiCategorizationService
private logUsage(model: string, tokens: number) {
  // Log do analytics
  // Aktualizuj licznik koszt√≥w
  // Alert gdy przekroczony bud≈ºet
}
```

---

**Rekomendacja Finalna**:
- **Start**: `meta-llama/llama-3.2-3b-instruct:free` (darmowy)
- **Production**: `openai/gpt-4o-mini` (najlepszy stosunek ceny do jako≈õci)
- **Premium**: `anthropic/claude-3.5-sonnet` (najwy≈ºsza jako≈õƒá)

